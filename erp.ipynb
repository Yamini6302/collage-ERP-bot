{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9c826d18",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#code for displaying responses\n",
    "from textblob import TextBlob\n",
    "import random\n",
    "import json\n",
    "import pickle\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "intents = json.loads(open('intent(1).json').read())\n",
    "words = pickle.load(open('words_erp.pkl','rb'))\n",
    "classes = pickle.load(open('classes_erp.pkl','rb'))\n",
    "model = load_model('chatbot_erp.h5')\n",
    "\n",
    "def clean_up_sentence(sentence):\n",
    "    sentence_words = nltk.word_tokenize(sentence)\n",
    "    sentence_words = [lemmatizer.lemmatize(word) for word in sentence_words]\n",
    "    return sentence_words\n",
    "\n",
    "def bag_of_words(sentence):\n",
    "    sentence_words = clean_up_sentence(sentence)\n",
    "    bag = [0]*len(words)\n",
    "    for w in sentence_words:\n",
    "        for i,word in enumerate(words):\n",
    "            if word == w:\n",
    "                bag[i] = 1\n",
    "    return np.array(bag)\n",
    "\n",
    "def predict_class(sentence):\n",
    "    sentence=str(sentence)\n",
    "    print(sentence)\n",
    "    bow = bag_of_words(sentence)\n",
    "    res = model.predict(np.array([bow]))[0]\n",
    "    ERROR_THRESHOLD = 0.25\n",
    "    results = [[i,r] for i,r in enumerate(res) if r>ERROR_THRESHOLD ]\n",
    "#     print(results)\n",
    "    \n",
    "    results.sort(key=lambda x: x[1], reverse = True)\n",
    "    return_list = []\n",
    "    if results:\n",
    "        for r in results:\n",
    "            return_list.append({'intent':classes[r[0]],'probability':str([r[1]])})\n",
    "        print(return_list)\n",
    "        return return_list[0]  #i am only printing response of higher probability tag\n",
    "    else:\n",
    "        return return_list\n",
    "\n",
    "def get_response(intents,tag):\n",
    "    res=\"\"\n",
    "    print(tag)\n",
    "    for i in intents['intents']:\n",
    "        if i['tag']==tag:\n",
    "            print(\"_______hi____\")\n",
    "            return(random.choice(i['responses']))\n",
    "        else:\n",
    "            continue          \n",
    "            \n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    while True:\n",
    "        count=1\n",
    "        txt = input(\"\")\n",
    "        message=TextBlob(txt).correct()\n",
    "        prediction = predict_class(message)\n",
    "        if prediction:\n",
    "            tag= prediction['intent']\n",
    "            res = get_response(intents,tag)\n",
    "            if res:\n",
    "                print(res)\n",
    "        else:\n",
    "            print(\"Sorry, I don't have any information about that.\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "236985f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 112ms/step\n",
      "[{'intent': 'greeting', 'probability': '[0.9999987]'}]\n",
      "_______hi____\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "[{'intent': 'attendance_check', 'probability': '[0.99925536]'}]\n",
      "_______hi____\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "[{'intent': '18', 'probability': '[0.99999666]'}]\n",
      "_______hi____\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "[{'intent': 'attendance_check', 'probability': '[0.9832897]'}]\n",
      "_______hi____\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "[{'intent': '7', 'probability': '[0.8550381]'}]\n",
      "_______hi____\n"
     ]
    }
   ],
   "source": [
    "from tkinter import scrolledtext, Entry, Button, END\n",
    "from textblob import TextBlob\n",
    "import random\n",
    "import json\n",
    "import pickle\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from tensorflow.keras.models import load_model\n",
    "import datetime\n",
    "\n",
    "# Load intents, words, and classes from pickle files\n",
    "intents = json.loads(open('intent(1).json').read())\n",
    "words = pickle.load(open('words_erp.pkl', 'rb'))\n",
    "classes = pickle.load(open('classes_erp.pkl', 'rb'))\n",
    "model = load_model('chatbot_erp.h5')\n",
    "domain_specific_words = [\"proctor\",\"parent\", \"'s\", 'Au', 'I', 'ID', 'USN', 'a', 'address', 'admission', 'app', 'appreciate', 'are', 'assessment', 'attendance', 'attendnce', 'auid', 'birth', 'book', 'built', 'bye', 'can', 'catch', 'change', 'check', 'class', 'classroom', 'collage', 'college', 'contact', 'could', 'course', 'coursera', 'created', 'daily', 'dance', 'date', 'day', 'department', 'detail', 'determine', 'did', 'displayed', 'do', 'email', 'emmergency', 'erp', 'exam', 'farewell', 'fee', 'feedback', 'find', 'for', 'from', 'give', 'going', 'good', 'goodbye', 'hand', 'have', 'hello', 'help', 'helpful', 'hey', 'hi', 'history', 'how', 'i', 'ia', 'icecream', 'id', 'idiot', 'in', 'information', 'internal', 'internals', 'is', 'it', 'know', 'later', 'location', 'logout', 'love', 'made', 'mark', 'me', 'modify', 'much', 'my', 'name', 'need', 'nonsense', 'notification', 'now', 'number', 'of', 'parent', 'password', 'pay', 'payment', 'phone', 'please', 'proctor', 'profile', 'rate', 'receipt', 'record', 'reset', 'revoir', 'room', 'score', 'section', 'see', 'semester', 'should', 'sing', 'song', 'stepts', 'student', 'support', 'table', 'teacher', 'term', 'thank', 'thanks', 'that', 'the', 'there', 'time', 'timetable', 'to', 'transaction', 'udpate', 'uniform', 'up', 'update', 'usn', 'very', 'view', 'want', 'were', 'what', 'where', 'which', 'who', 'wise', 'you', 'your']\n",
    "\n",
    "# Initialize WordNet lemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# Function to clean up the sentence\n",
    "def clean_up_sentence(sentence):\n",
    "    sentence_words = nltk.word_tokenize(sentence)\n",
    "    sentence_words = [lemmatizer.lemmatize(word) for word in sentence_words]\n",
    "    return sentence_words\n",
    "\n",
    "# Function to create bag of words\n",
    "def bag_of_words(sentence):\n",
    "    sentence_words = clean_up_sentence(sentence)\n",
    "    bag = [0] * len(words)\n",
    "    for w in sentence_words:\n",
    "        for i, word in enumerate(words):\n",
    "            if word == w:\n",
    "                bag[i] = 1\n",
    "    return np.array(bag)\n",
    "\n",
    "# Function to predict intent class\n",
    "def predict_class(sentence):\n",
    "    sentence = str(sentence)\n",
    "    bow = bag_of_words(sentence)\n",
    "    res = model.predict(np.array([bow]))[0]\n",
    "    ERROR_THRESHOLD = 0.5  # Increased from 0.6 to 0.7\n",
    "    results = [[i, r] for i, r in enumerate(res) if r > ERROR_THRESHOLD]\n",
    "    results.sort(key=lambda x: x[1], reverse=True)\n",
    "    return_list = []\n",
    "\n",
    "    if results:\n",
    "        return_list.append({'intent': classes[results[0][0]], 'probability': str([results[0][1]])})\n",
    "        print(return_list)\n",
    "        return return_list[0]\n",
    "    else:\n",
    "        return_list.append({'intent': 'unrecognized', 'probability': '0.0'})\n",
    "        return return_list[0]\n",
    "\n",
    "# Function to get response based on intent\n",
    "def get_response(intents, tag):\n",
    "    for i in intents['intents']:\n",
    "        if i['tag'] == tag:\n",
    "            print(\"_______hi____\")\n",
    "            return random.choice(i['responses'])\n",
    "    print(\"_______hi____\")\n",
    "    return \"Sorry, I don't have any information about that.\"\n",
    "\n",
    "# Function to handle unrecognized intent\n",
    "def handle_unrecognized_intent():\n",
    "    print(\"Sorry, I don't have any information about that.\")\n",
    "\n",
    "# Function to send a message and get a response\n",
    "def send_message():\n",
    "    user_input = entry.get()\n",
    "    \n",
    "    # Split the input into words\n",
    "    words_in_input = user_input.split()\n",
    "\n",
    "    # Apply TextBlob correction selectively\n",
    "    corrected_words = []\n",
    "    for word in words_in_input:\n",
    "        if word.lower() not in domain_specific_words:\n",
    "            corrected_word = str(TextBlob(word).correct())\n",
    "            corrected_words.append(corrected_word)\n",
    "        else:\n",
    "            corrected_words.append(word)\n",
    "\n",
    "    # Join the corrected words back into a sentence\n",
    "    corrected_input = ' '.join(corrected_words)\n",
    "\n",
    "    prediction = predict_class(corrected_input)\n",
    "    tag = prediction['intent']\n",
    "\n",
    "    # Initialize response variable\n",
    "    response = \"\"\n",
    "    if tag == 'unrecognized':\n",
    "        response = \"Sorry, I don't have any information about that.\"\n",
    "    else:\n",
    "        # Get the response based on the intent\n",
    "        response = get_response(intents, tag)\n",
    "\n",
    "    current_time = datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "    chat_display.insert(tk.END, f\"{current_time} - You: \" + user_input + \"\\n\")\n",
    "    chat_display.insert(tk.END, f\"{current_time} - Chatbot: \" + response +\"\\n\"+\"------------------------------------------------\"+ \"\\n\")\n",
    "\n",
    "    # Clear the entry field after sending the message\n",
    "    entry.delete(0, tk.END)\n",
    "\n",
    "# Create the main window\n",
    "window = tk.Tk()\n",
    "window.title(\"Chatbot Interface\")\n",
    "\n",
    "# Apply QSS styles from styles.qss file using configure method\n",
    "window.configure(background='#2E2E2E')\n",
    "\n",
    "# Create and configure the chat display\n",
    "chat_display = scrolledtext.ScrolledText(window, width=50, height=20, wrap=tk.WORD)\n",
    "chat_display.grid(row=0, column=0, columnspan=2, padx=10, pady=10)\n",
    "\n",
    "# Create the entry for user input\n",
    "entry = Entry(window, width=40)\n",
    "entry.grid(row=1, column=0, padx=10, pady=10)\n",
    "entry.configure(background='#333333', fg='#FFFFFF', bd=2, relief='solid', insertbackground='#4CAF50')\n",
    "\n",
    "# Create the send button\n",
    "send_button = Button(window, text=\"Send\", command=send_message)\n",
    "send_button.grid(row=1, column=1, padx=10, pady=10)\n",
    "send_button.configure(background='#4CAF50', fg='white', bd=0, padx=20, pady=10, font=('Arial', 16), cursor='hand2')\n",
    "\n",
    "# Start the GUI main loop\n",
    "window.mainloop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a6e6f33b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pandas in c:\\programdata\\anaconda3\\lib\\site-packages (1.4.2)\n",
      "Collecting pandas\n",
      "  Downloading pandas-2.1.4-cp39-cp39-win_amd64.whl.metadata (18 kB)\n",
      "Requirement already satisfied: numpy<2,>=1.22.4 in c:\\users\\pragati\\appdata\\roaming\\python\\python39\\site-packages (from pandas) (1.22.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas) (2021.3)\n",
      "Collecting tzdata>=2022.1 (from pandas)\n",
      "  Downloading tzdata-2023.4-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: six>=1.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Downloading pandas-2.1.4-cp39-cp39-win_amd64.whl (10.8 MB)\n",
      "   ---------------------------------------- 10.8/10.8 MB 7.7 MB/s eta 0:00:00\n",
      "Downloading tzdata-2023.4-py2.py3-none-any.whl (346 kB)\n",
      "   ---------------------------------------- 346.6/346.6 kB 4.3 MB/s eta 0:00:00\n",
      "Installing collected packages: tzdata, pandas\n",
      "Successfully installed pandas-2.1.4 tzdata-2023.4\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.3.1 -> 23.3.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade pandas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc37009b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
